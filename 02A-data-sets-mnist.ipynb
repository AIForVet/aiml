{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFmqQPj3NzUW"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AIForVet/aiml/blob/main/02A-data-sets-mnist.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The MINST dataset stands for \"Modified National Institute of Standards and Technology\". The dataset contains a large collection of handwritten digits that is commonly used for training various image processing systems. The dataset was created by re-mixing samples from NIST's original datasets, which were taken from American Census Bureau employees and high school students. It is designed to help scientists develop and test machine learning algorithms in pattern recognition and machine learning. It contains 60,000 training images and 10,000 testing images, each of which is a grayscale image of size 28x28 pixels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIVAvpI0_PXp"
      },
      "source": [
        "## Loading MNIST dataset using TensorFlow/Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3r2u7W3bbzb"
      },
      "source": [
        "This code snippet load mnist dataset keras example using Keras, retrieves the training images and labels, and then plots four images in a row with their corresponding labels. Each image is displayed in grayscale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvi0GlIAb2o7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "# Print 4 images in a row\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.imshow(X_train[i], cmap='gray')\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le83fSkQAaPn"
      },
      "source": [
        "## Loading MNIST dataset Using PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this examples we will explore to load mnist dataset pytorch example. PyTorch offers a similar utility through torchvision.datasets, which is very convenient, especially when combined with torchvision.transforms to perform basic preprocessing like converting images to tensor format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxEDPDoobWcJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import ssl\n",
        "\n",
        "# Disable SSL verification\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "# Define the transformation to convert images to PyTorch tensors\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "# Load the MNIST dataset with the specified transformation\n",
        "mnist_pytorch = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "# Create a DataLoader to load the dataset in batches\n",
        "train_loader_pytorch = torch.utils.data.DataLoader(mnist_pytorch, batch_size=1, shuffle=False)\n",
        "# Create a figure to display the images\n",
        "plt.figure(figsize=(15, 3))\n",
        "# Print the first few images in a row\n",
        "for i, (image, label) in enumerate(train_loader_pytorch):\n",
        "    if i < 5:  # Print the first 5 samples\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(image[0].squeeze(), cmap='gray')\n",
        "        plt.title(f\"Label: {label.item()}\")\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        break  # Exit the loop after printing 5 samples\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handwritten Digit Recognition using Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to implement a handwritten digit recognition app using the MNIST dataset. We will be using a special type of deep neural network called Convolutional Neural Networks. In the end, we are going to build a GUI in which you can draw the digit and recognize it straight away.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install numpy, tensorflow, keras, pillow,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import the libraries and load the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Keras library already contains some datasets and MNIST is one of them. So we can easily import the dataset and start working with it. The `mnist.load_data()` method returns us the training data, its labels, and also the testing data and its labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image data cannot be fed directly into the model so we need to perform some operations and process the data to make it ready for our neural network. The dimension of the training data is (60000, 28, 28). The CNN model will require one more dimension so we reshape the matrix to shape (60000, 28, 28, 1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 10\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A CNN model generally consists of convolutional and pooling layers. It works better for data that are represented as grid structures, which is why CNNs work well for image classification problems. The dropout layer is used to deactivate some of the neurons during training, reducing overfitting of the model. We will then compile the model with the Adadelta optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `model.fit()` function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size.\n",
        "\n",
        "It takes some time to train the model. After training, we save the weights and model definition in the `mnist.h5` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "print(\"The model has successfully trained\")\n",
        "\n",
        "model.save('mnist.h5')\n",
        "print(\"Saving the model as mnist.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have 10,000 images in our dataset which will be used to evaluate how well our model works. The testing data was not involved in the training process, so it is new data for our model. The MNIST dataset is well-balanced, so we can expect to achieve around 99% accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create GUI to predict digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now for the GUI, we have created a new file where we build an interactive window to draw digits on a canvas. With a button, we can recognize the digit. The Tkinter library is part of the Python standard library. We have created a function `predict_digit()` that takes the image as input and then uses the trained model to predict the digit.\n",
        "\n",
        "Then we create the `App` class, which is responsible for building the GUI for our app. We create a canvas where we can draw by capturing the mouse events. With a button, we trigger the `predict_digit()` function and display the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from tkinter import *\n",
        "import tkinter as tk\n",
        "import win32gui\n",
        "from PIL import ImageGrab, Image\n",
        "import numpy as np\n",
        "\n",
        "model = load_model('mnist.h5')\n",
        "\n",
        "def predict_digit(img):\n",
        "    #resize image to 28x28 pixels\n",
        "    img = img.resize((28,28))\n",
        "    #convert rgb to grayscale\n",
        "    img = img.convert('L')\n",
        "    img = np.array(img)\n",
        "    #reshaping to support our model input and normalizing\n",
        "    img = img.reshape(1,28,28,1)\n",
        "    img = img/255.0\n",
        "    #predicting the class\n",
        "    res = model.predict([img])[0]\n",
        "    return np.argmax(res), max(res)\n",
        "\n",
        "class App(tk.Tk):\n",
        "    def __init__(self):\n",
        "        tk.Tk.__init__(self)\n",
        "\n",
        "        self.x = self.y = 0\n",
        "\n",
        "        # Creating elements\n",
        "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
        "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
        "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
        "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
        "\n",
        "        # Grid structure\n",
        "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
        "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
        "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
        "        self.button_clear.grid(row=1, column=0, pady=2)\n",
        "\n",
        "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
        "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
        "\n",
        "    def clear_all(self):\n",
        "        self.canvas.delete(\"all\")\n",
        "\n",
        "    def classify_handwriting(self):\n",
        "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
        "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
        "        im = ImageGrab.grab(rect)\n",
        "\n",
        "        digit, acc = predict_digit(im)\n",
        "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
        "\n",
        "    def draw_lines(self, event):\n",
        "        self.x = event.x\n",
        "        self.y = event.y\n",
        "        r=8\n",
        "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
        "\n",
        "app = App()\n",
        "mainloop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Instructions for Students\n",
        "\n",
        "1. **Understand the Dataset**: Familiarize yourself with the MNIST dataset, which contains handwritten digits. This dataset is commonly used for training image processing systems.\n",
        "\n",
        "2. **Loading Data**: Learn how to load the MNIST dataset using both TensorFlow/Keras and PyTorch. Observe the differences and similarities in the loading process.\n",
        "\n",
        "3. **Data Visualization**: Visualize the dataset by plotting sample images. This helps in understanding the structure and format of the data.\n",
        "\n",
        "4. **Preprocessing**: Preprocess the data to make it suitable for training a Convolutional Neural Network (CNN). This includes reshaping the data and normalizing pixel values.\n",
        "\n",
        "5. **Model Creation**: Create a CNN model using Keras. Understand the architecture of the model, including convolutional layers, pooling layers, and dropout layers.\n",
        "\n",
        "6. **Training the Model**: Train the model using the training dataset. Pay attention to the parameters used in the `model.fit()` function, such as batch size and number of epochs.\n",
        "\n",
        "7. **Model Evaluation**: Evaluate the trained model using the test dataset. Understand the metrics used for evaluation, such as accuracy and loss.\n",
        "\n",
        "8. **Building a GUI**: Learn how to build a graphical user interface (GUI) using Tkinter. This GUI will allow you to draw digits and recognize them using the trained model.\n",
        "\n",
        "9. **Experiment and Modify**: Experiment with different model architectures, hyperparameters, and preprocessing techniques. Observe how these changes affect the model's performance.\n",
        "\n",
        "10. **Documentation**: Document your workflow, observations, and results. This will help in understanding the process and sharing your findings with others.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
