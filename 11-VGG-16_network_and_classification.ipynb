{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGko22P6dTYc"
      },
      "source": [
        "# VGG-16 Network and Image Classification Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wj3s_kxMWKb"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AIForVet/aiml/blob/main/11-VGG-16_network_and_classification.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bmuBkr2dWPw"
      },
      "source": [
        "In this notebook, you can try out how convolutional neural networks actually work. We will use the VGG-16 network and test it in an image classification task. We have as many as 1000 classes at our disposal!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQm4Zz4udn9C"
      },
      "source": [
        "At the very beginning, we will load the standard libraries needed for further work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTwaUQT7e2Az"
      },
      "outputs": [],
      "source": [
        "#%pip install pandas\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y69SEXuduY1"
      },
      "source": [
        "Specifically, from the TensorFlow library we load the pre-trained VGG-16 model. When loading this model, we need to indicate that we want to use the model that was trained on images from the ImageNet dataset. We do this by setting the `weights` argument of the `VGG16` function to `imagenet`. The loading of the model itself may take a bit of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-tDnaoVhN_C"
      },
      "outputs": [],
      "source": [
        "#%pip install tensorflow\n",
        "#%pip install --upgrade numpy\n",
        "\n",
        "from tensorflow.keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOaSmbpYh-kF",
        "outputId": "a6c00104-cb16-4594-da12-8eff14e6fa0b"
      },
      "outputs": [],
      "source": [
        "model = VGG16(weights='imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOOiFBeLeRHa"
      },
      "source": [
        "Next, we will check the layers that make up this network. Don't be confused if you don't understand all the details displayed. It is important to know that the input is expected to be a 224x224 pixel color image (hence the 224, 224, 3 next to the input layer) and that the output is one of 1000 classes. You can compare the output with the VGG-16 model diagram we discussed to discover more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHv2WfiklfI",
        "outputId": "5155156b-6b83-4066-c743-8e393ad121d6"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loQj6Ud6k5GC"
      },
      "source": [
        "We can see that the number of parameters of this network is over 138 million. We will not train the network, but we will only use the pre-trained model. Therefore, it is important not to change the model parameters during operation - each one has its own contribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DhFM2IKgO9R"
      },
      "source": [
        "The idea is to test the network with an arbitrary image from the web. To achieve this, we will use a couple of libraries. The PIL library is the standard Python library for working with images, while we will use the urllib and io libraries to load the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYUO6ykWllwn"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from urllib import request\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqXvqEbXgnSC"
      },
      "source": [
        "The `load_image` function will help us fetch any image we want from the web. It is enough to provide it with the URL path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2ijPxLMypSw"
      },
      "outputs": [],
      "source": [
        "def load_image(url_path):\n",
        "    response = request.urlopen(url_path).read()\n",
        "    return Image.open(BytesIO(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXHKpqrGg_ez"
      },
      "source": [
        "We have chosen an image of a golden retriever! By changing the path in the `image_url` variable, you can set the image you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWHye3QozOMX"
      },
      "outputs": [],
      "source": [
        "image_url = 'https://images.unsplash.com/photo-1558788353-f76d92427f16?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=738&q=80' # https://unsplash.com/photos/x5oPmHmY3kQ\n",
        "test_image = load_image(url_path=image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBhegptahUUm"
      },
      "source": [
        "Now we will display the loaded image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "RVc39p2ghYPY",
        "outputId": "6e35cb82-f4e9-4934-ca75-0ae8ba038cc4"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWHs4kOe9RQY"
      },
      "source": [
        "When choosing an image, it is important to keep in mind that the class of the object in the image must be known to the model. Since the VGG-16 model is trained on over 1.2 million images, it recognizes a lot of objects, even 1000 different ones. As it has learned about the golden retriever, we can expect a good result. If we give the model an image with an object it does not recognize, it will give us predictions of classes whose images most resemble ours. We will see at the end which object classes resemble the golden retriever."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwlIoPXknxc"
      },
      "source": [
        "Since the image that we need to pass to the model needs to be specially prepared, the following section covers the preparations.\n",
        "\n",
        "We will also load a couple of libraries that will make our work easier. It is common for the community to share all accompanying functionalities that are useful in these steps when sharing models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxAnnoodlG4J"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V8qwGKniGb0"
      },
      "source": [
        "First, we will prepare the image by setting its dimensions to 224x224 and specifying that it uses three color channels RGB.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j2DA-lk0GYV"
      },
      "outputs": [],
      "source": [
        "test_image = test_image.resize((224, 224))\n",
        "test_image = test_image.convert('RGB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "YLD0I5S3ibR6",
        "outputId": "44d23630-0e7e-42c0-e298-80a8f39c42f5"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BoB4sGVlplb"
      },
      "source": [
        "Next, we will ensure that the image is in the appropriate matrix format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGQj_Su9lvfW",
        "outputId": "66df66dd-8327-4b21-fa8e-9822cfe9ba62"
      },
      "outputs": [],
      "source": [
        "matrix_form_test_image = image.img_to_array(test_image)\n",
        "print(matrix_form_test_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WhcWitel0IU"
      },
      "source": [
        "As you know, networks always work with data batches. Therefore, we will create a batch that contains our image. As you would expect, its dimension will be 1 x 224 x 224 x 3 because we have only one image in the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TK996ZL1zQ_",
        "outputId": "0f5eda6c-ab7f-4171-a3f2-b90a8a53fd9f"
      },
      "outputs": [],
      "source": [
        "batch = np.expand_dims(matrix_form_test_image, axis=0)\n",
        "print(f'(number_of_test_images, height, width, number_of_channels) = {batch.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjp6x9oTitz7"
      },
      "source": [
        "Next is the part that deals with numerical preprocessing of the image in the form of normalization. A special function `preprocess_input` that accompanies the model will help us with this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ekjx-CL4YmD"
      },
      "outputs": [],
      "source": [
        "test_image_batch = preprocess_input(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYVNcXo6mqUz"
      },
      "source": [
        "Since we have finished the preparation, we can now use the model for the classification task. The function that will help us in this part is called `predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnueslgtm7Cm",
        "outputId": "548d5f17-47d6-45c7-d988-c53e61109ac6"
      },
      "outputs": [],
      "source": [
        "model_predictions = model.predict(test_image_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOdo7SPJm_hT"
      },
      "source": [
        "The obtained model predictions represent the probabilities of our image belonging to each of the 1000 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdDEtQRRnGyH",
        "outputId": "1e0831a6-ee42-49d1-ff43-c0884444b361"
      },
      "outputs": [],
      "source": [
        "model_predictions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcGJ6QuQnYe4"
      },
      "source": [
        "To extract the class to which our image belongs, we can use the `decode_predictions` function, which will return the probabilities and names of the 5 most likely classes. This will give us insight into how confident the model is during classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7zIw9UJ7JXL",
        "outputId": "e62be103-b224-487d-8d2b-966efc9f1f19"
      },
      "outputs": [],
      "source": [
        "most_likely_classes = decode_predictions(model_predictions)[0]\n",
        "print(most_likely_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_WUS0_9oIu8"
      },
      "source": [
        "As we can see, in the first place is the class *golden retriever* with a probability of 0.8042132. To better follow the model output, we can also display it graphically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "hlZ2BsgB8q7L",
        "outputId": "ba066c62-a5b0-4f0a-a606-09b5e1a7cbfb"
      },
      "outputs": [],
      "source": [
        "class_names = [item[1] for item in most_likely_classes]\n",
        "class_probabilities = [item[2] for item in most_likely_classes]\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(class_names, class_probabilities, color=['teal', 'yellow', 'green', 'blue', 'orange'])\n",
        "plt.title('Top 5 Most Likely Classes')\n",
        "plt.ylabel('Probability')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB2q6aWmC2cp"
      },
      "source": [
        "We see that the model has predicted with high confidence that the image we selected is a golden retriever. Some of the other classes the model considered are other types of retrievers. Interestingly, a tennis ball also appeared in the list of results. :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maCJPPgZqRcN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
